{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Analytics Basics in Python Series**\n",
        "\n"
      ],
      "metadata": {
        "id": "V5eA4LpGy8Oj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Chapter 1: Pandas DataFrames for Working with Tabular Data in Python**\n",
        "\n",
        "**Lecture from: Michael Pyrcz, Associate Professor, The University of Texas at Austin**\n",
        "\n",
        "*Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions*"
      ],
      "metadata": {
        "id": "8_4gZKb-zIH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tabular Data**\n",
        "\n",
        "This is the tutorial for/demonstration of **Tabular Data Structures in Python**. In Python, the common tool for dealing with Tabular Data Structures is the DataFrame from the Pandas Python package.\n",
        "\n",
        "This tutorial includes the methods and operations that would commonly be required for Engineers and Scientists working with Tabular Data Structures for the purpose of:\n",
        "1. Data Checking and Cleaning.\n",
        "2. Data Mining/Inferential Data Analysis\n",
        "3. Data Analytics/ Building Predictive Models with Geostatistics and Machine Learning \n",
        "\n",
        "Learning work with Pandas DataFrame is essential for dealing with tabular data (e.g. well data) in subsurface modeling workflows and for subsurface machine learning."
      ],
      "metadata": {
        "id": "UVEPGn1Uz5vi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tabular Data Structures**\n",
        "In Python we will commonly store our data in two formats, tables and arrays. For example data with typically multiples features $1,2,\\dots,m$ over $1,2,\\dots,n$ samples we work with table. For exhaustive maps and models usually representing a single feature on a regular grid over $1,2,\\dots,n_i$ for $i = 1,\\dots,n_{\\text{dim}}$ we will work with arrays.\n",
        "\n",
        "|$X^1$      | $X^2$    | $\\ldots$   | $X^m$   | $y$    |\n",
        "|-----------|----------|------------|---------|---------|\n",
        "|$X^1_1$      | $X^2_1$    | $\\ldots$   | $X^m_1$   | $y_1$    |\n",
        "|$X^1_2$      | $X^2_2$    | $\\ldots$   | $X^m_2$   | $y_2$    |\n",
        "|$\\ldots$      | $\\ldots$    | $\\ldots$   | $\\ldots$   | $\\ldots$    |\n",
        "|$X^1_n$      | $X^2_n$    | $\\ldots$   | $X^m_n$   | $y_n$    |\n",
        "\n",
        "\n",
        "**pandas** Python provides a convinient DataFrame object for working with data in a table and numpy package provides a convinient ndarray object for working with gridded data. In the following tutorial will focus on DataFrames althouugh we will utilize ndarrays a couple of times. There is another section on Gridded Data Structures that focuses on ndarrays."
      ],
      "metadata": {
        "id": "1aB7G2851fzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Project Goal**\n",
        "Learn the basics for working with Tabular Data Structures in Python with Pandas DataFrames."
      ],
      "metadata": {
        "id": "tH8l4MK31f_z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load the required libraries**"
      ],
      "metadata": {
        "id": "RcXDX7Tv4oOn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE1yu4EhZ-n1"
      },
      "outputs": [],
      "source": [
        "import os                           # operating system\n",
        "import numpy as np                  # arrays and matrix math\n",
        "import pandas as pd                 # DataFrames\n",
        "import matplotlib.pyplot as plt     # Plotting"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Loading Data**\n",
        "Let's load the provided multivariate, spatial dataset. '2D_MV_200wells.csv' is available at https://github.com/GeostatsGuy/GeoDataSets. \n",
        "\n",
        "It is a comma delimited file with $X$ and $Y$ coordinates, facies 1 and 2 (1 is sandstone and 2 is interbedded sand and mudstone), porosity (fraction), permeability (mDarcy) and acoustic impedance (kg/m2s*10^6).\n",
        "\n",
        "We load it with the pandas 'read_csv' function into a dataframe called 'df' and then preview it by printing a slice and utilizing the 'head' DataFrame member function (with a nice and clean format) "
      ],
      "metadata": {
        "id": "txIxN0SS5PoH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_csv('2D_MV_200wells.csv')  # read in DataFrame (.csv)\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/GeostatsGuy/GeoDataSets/master/2D_MV_200wells.csv')\n",
        "print(df.iloc[:5,:])   # view the first 5 samples\n",
        "df.head(n=5)              # view the first 5 (default) samples"
      ],
      "metadata": {
        "id": "jEm5hhYH6r6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Check the Tabular Data**\n",
        "\n",
        "It is useful to review the summary statistics of our loaded DataFrame. \n",
        "This can be accomplished with the \"describe\" DataFrame member function. We transpose to switch the axes for ease of visualization."
      ],
      "metadata": {
        "id": "1K0ms9MM7q_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe().transpose()      # summary of statistics"
      ],
      "metadata": {
        "id": "l9Zo4GZO7liP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Rename Features**\n",
        "\n",
        "Let's rename the facies, permeability and acoustic impedance for convinience."
      ],
      "metadata": {
        "id": "Nbcv7i4C8dKf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={'facies_threshold_0.3':'facies', 'permeability':'perm', 'acoustic_impedance':'ai' })\n",
        "df.head()"
      ],
      "metadata": {
        "id": "58Bo6wJE8UW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Slicing DataFrame**\n",
        "\n",
        "It is straightforward to extract subsets from a DataFrame to make a new DataFrame.\n",
        "* We use [my_DataFrame].iloc() with indexes, integers for rows and columns.\n",
        "* This is useful for cleaning up data by removing features that are no longer of interest.\n"
      ],
      "metadata": {
        "id": "IYY9BdLf9O3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset = df.iloc[0:4,2:7]\n",
        "df_subset.head()"
      ],
      "metadata": {
        "id": "W6YTP5f29JHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Slicing DataFrame**\n",
        "It is straightforward to extract subsets from a DataFrame to make a new DataFrame.\n",
        "* We use [my_DataFrame].loc() with column labels and integers for rows, could be more legible.\n",
        "* This is useful for cleaning up data by removing features that no longer of interest.\n"
      ],
      "metadata": {
        "id": "w6jvNksN-eDg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_subset2 = df.loc[0:4,['X', 'facies', 'perm','ai']]\n",
        "df_subset2.head()"
      ],
      "metadata": {
        "id": "RuijC6YX-PfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deep and Shallow Copies**\n",
        "\n",
        "We must know the difference, or we will eventually run into an issue.\n",
        " * **shallow copy:** - point to the same memory, change one and both are changed.\n",
        " * **deep copy**: - make a new copy in memory, change one only one changes."
      ],
      "metadata": {
        "id": "inWTxlHq_X_X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Deep Copy example**\n",
        "\n",
        "Let's demonstrate a deep copy with the DataFrame member function, [my_DataFrame].copy()\n",
        "* note the [my_DataFrame].loc() member function is a deep copy."
      ],
      "metadata": {
        "id": "3cwtsBed_6fq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_deep_copy = df.copy(deep=True)\n",
        "df_deep_copy.loc[4,'ai'] = 4.0\n",
        "df.head()"
      ],
      "metadata": {
        "id": "qw2XkS4w_T3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Shallow Copy example**\n",
        "Let's demonstrate a shallow copy with the DataFrame member function, [my_DataFrame].copy()"
      ],
      "metadata": {
        "id": "SCTpeHXLAlpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_shallow_copy = df.copy(deep=False)\n",
        "df_shallow_copy.loc[4,'ai']=4.0\n",
        "df.head()"
      ],
      "metadata": {
        "id": "kwBH6SjYAhCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Add a new feature**\n",
        "\n",
        "It is also easy to add a column into our dataframe\n",
        "* Note, we assume that the array is in the same order as the samples in the DataFrame.\n",
        "\n",
        "This could be an issue if any rows were removed from either before adding, etc. To demonstrate we make a 1D numpy array of zeros using 'zeros' function and add it to our data frame with the feature name indicated as 'zero'."
      ],
      "metadata": {
        "id": "YMPBykdvBDMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero = np.zeros(200)                # make an array of zeros\n",
        "df['zero'] = pd.Series(zero)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "4IIWe8KdA9h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove a feature**\n",
        "\n",
        "We can also remove features from our DataFrame\n",
        "* We do this with the member function, [my_DataFrame].drop()\n",
        "* We just have the given the column name and by indicating axis=1 we specify to drop a column.\n"
      ],
      "metadata": {
        "id": "M_J69NsyCVfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('zero', axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "pw9uoPnNCQPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Remove a sample**\n",
        "\n",
        "We can also remove samples from the DataFrame\n",
        "* We do this with the member function, [my_DataFrame].drop()\n",
        "* We just have given the sample index and by indicating axis= 0 we specify to drop a sample."
      ],
      "metadata": {
        "id": "W5VDKZHUC93h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(3,axis=0)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "UQ0qOt3tC49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Feature Engineering**\n",
        "\n",
        "We may want to make a new feature by using mathematical operators applied to existing features.\n",
        "* For example, we can make a porosity feature in percentage instead of fraction, called 'porosity100'.\n",
        "* Or a ratio of permeability divided by porosity, called 'permpor', may be useful for subsequence calculations such as the Lorenz Coefficient."
      ],
      "metadata": {
        "id": "5OdFv8VvDguQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['porosity100'] = df['porosity']*100             # add a new column with porosity in percentage\n",
        "df['permpor'] = df['perm']/df['porosity']          # add a new feature with the ratio of perm/porosity\n",
        "df.head()"
      ],
      "metadata": {
        "id": "oKuybpEgDbHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conditional Manipulation**\n",
        "\n",
        "We could also use conditional statements when assighing values to a new feature.\n",
        "* For example, we could have a categorical porosity measure for high and low porosity, called \"tporosity\"."
      ],
      "metadata": {
        "id": "gvJv_amuEy4u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['tporosity'] = np.where(df['porosity']>=0.12, 'high', 'low')    # make a new categorical feature\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Whp0gQzKFUwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conditional Manipulation, More than One Feature**\n",
        "\n",
        "Here's an example where we use a conditonal statement to assign a very low permeability value (0.0001mD) for all porosity values below the threshold."
      ],
      "metadata": {
        "id": "JBmEqg7gFrzV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['perm_cutoff'] = np.where(df['porosity'] >= 0.12, df['perm'], 0.0001)  # new feature with conditinal truncation\n",
        "df.head(n=10)"
      ],
      "metadata": {
        "id": "k7POwO7ZFiki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Finding Missing Data**\n",
        "\n",
        "What about missing or invalid values?\n",
        "\n",
        "* Let's assign a single porosity value to 'NaN', 'not a number', indicating a missing or eroneous value.\n",
        "* We will then check for the number of NaN values in our dataframe.\n",
        "* Then we can search for and display the sample with the NaN porosity value. "
      ],
      "metadata": {
        "id": "9SsNaFUCGvxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[1,'porosity'] = np.NaN\n",
        "print('Number of null values in our dataset = ' + str(df.isnull().sum().sum()))  # count missing value\n",
        "nan_rows = df[df['porosity'].isnull()]                                      # find the samples with missing values\n",
        "print(nan_rows)  # Print that samples"
      ],
      "metadata": {
        "id": "UwWeenVPGgkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Likewise Deletion**\n",
        "\n",
        "We can see that sample 1 has a NaN porosity value. Now we may choose to remove the sample with the NaN.\n",
        "* The 'dropna' DataFrame member function will remove all samples with NaN entries from the entire DataFrame.\n",
        "* By visualizing the index at the left of the DataFrame preview we can confirm that sample 1 is removed."
      ],
      "metadata": {
        "id": "MV9nSeoDIatv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(how='any') #likewise deletion\n",
        "df.head()"
      ],
      "metadata": {
        "id": "JiVMAwyAIRRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conditional Slicing**\n",
        "\n",
        "One could extract samples into a new DataFrame with multiple criteria.\n",
        "* We make a new DataFrame with all good permeability and all good porosity."
      ],
      "metadata": {
        "id": "xcuBk0Q5Jgtk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_extract = df.loc[(df['porosity']>0.12) & (df['perm'] >10.0)] # extract with multiple conditions to a new dataframe\n",
        "df_extract.head(n=10)"
      ],
      "metadata": {
        "id": "gsokfnUCJQYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Making a New DataFrame from Scratch**\n",
        "\n",
        "It is also simple to build a new DataFrame from a set of 1D array.\n",
        "* Note, they must have the same size and be sorted consistently.\n",
        "* We will extract proposity and perm as arrays (if we remove '.values' they are extracted as Series and retaining the feature names)\n",
        "* We then use the pandas DataFrame command to make a new DataFrame with each 1D array and the column names specified as 'porosity' and 'permeability'"
      ],
      "metadata": {
        "id": "L4MYgAYxKSeB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "por = df['porosity'].values    # extract the porosity column as a vector\n",
        "perm = df['perm'].values            # extract the perm column as a vector\n",
        "df_new = pd.DataFrame({'porosity':por,'permeability':perm})\n",
        "df_new.head(n=7)\n"
      ],
      "metadata": {
        "id": "IWzTFp7QKKCO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Basic plotting**\n",
        "While I generally use MatPlotLib, Seaborn, etc. for plotting. Pandas has built in plotting functions."
      ],
      "metadata": {
        "id": "5VJCVIYVMT-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Line plots**\n",
        "\n",
        "Here's an example of line plot\n",
        "* there are various types to choose from, e.g. bar, box, scatter, etc."
      ],
      "metadata": {
        "id": "k-YSCSg7Mk7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['porosity'].plot(kind='line', color='blue')      # make a line plot\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Porosity (fraction)')\n",
        "plt.title('Dataframe Feature Line Plot')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oNnj80LqMLgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Histograms**\n",
        "\n",
        "Here's an example of histogram"
      ],
      "metadata": {
        "id": "uQ5bM3tINXcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['porosity'].plot(kind='hist', color='blue', edgecolor='k')\n",
        "plt.xlabel('Sample')\n",
        "plt.ylabel('Porosity (fraction)')\n",
        "plt.title('Dataframe Feature Histogram Plot')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "J_WljFFtNPN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Accessing the Data Feature**\n",
        "\n",
        "We can reach in and retrieve the actual raw information in the DataFrame including the column names and actual values as an bumpy array. We cannot edit them like this, but we can access and use this information. This includes:\n",
        "* **index** with the information about the sample index\n",
        "* **columns** with the names of the features\n",
        "* **values** with the data table entries as an 2D array"
      ],
      "metadata": {
        "id": "3JkuUdb5OGI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.index)         # get information about the index\n",
        "print(df.columns)       # get the list of feature names\n",
        "print(df.values)        # get the 2D array with all the table data"
      ],
      "metadata": {
        "id": "62JrjgNbNrcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Retrieving Values with DataFrames with [my_DataFrame].value()**\n",
        "\n",
        "We can read the values through the values member of DataFrames"
      ],
      "metadata": {
        "id": "Vo6hOLv6QWtN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "por1 = df.values[0,3]\n",
        "print('Porosity values for the sample 0 is ' + str(por1) + '.')"
      ],
      "metadata": {
        "id": "DnR0znRKQr0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Converting a Pandas DataFrame to a Numpy ndarray**\n",
        "\n",
        "We can copy the entire Dataframe to a ndarray."
      ],
      "metadata": {
        "id": "wOqXCx3nQW4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_array = df.to_numpy()     # Copy the DataFrame to an ndarray\n",
        "print('We just made a ' + str(type(df_array)))\n",
        "print('of shape ' + str(df_array.shape))"
      ],
      "metadata": {
        "id": "kEomQ1HDRSrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note this is a deep copy. If we change the ndarray, the DataFrame is not updated."
      ],
      "metadata": {
        "id": "BkKRi6smRwCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_array[2,1] = 10000\n",
        "df.head(n=3)"
      ],
      "metadata": {
        "id": "XY2_1n02RrxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Python Built-in functions on DataFrames**\n",
        "\n",
        "There are some Python built-in functions that accept a Dataframe as a argument."
      ],
      "metadata": {
        "id": "3rbURzpeSE6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Dataframe has ' + str(len(df)) + ' samples.')\n",
        "print('Dataframe\\'s features are ' + str(list(df)) + '.')"
      ],
      "metadata": {
        "id": "_SrDuCK6R9vn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Directly Editing DataFrames**\n",
        "\n",
        "Let's interact with the DataFrame more surgically, one feature and sample at a time.\n",
        "* We can use the [my_DataFrame].at() member function to access a single value.\n",
        "* This includes reading and writing \n",
        "* Alternatively we could use [my_DataFrame].loc(), used previously."
      ],
      "metadata": {
        "id": "OQV0la1dSs8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('The value of the first porosity sample was ' + str(df.at[0,'porosity']))\n",
        "df.at[0,'porosity'] = 0.2000 # set the new value for sample 1 of the porosity feature\n",
        "print('The value of porosity for sample 0 is now ' + str(df.loc[0,'porosity']) + '.')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Fae0So9FSn4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Saving a DataFrame to a File**\n",
        "\n",
        "It may be useful to write the DataFrame out for storage of curation and/or to be utilize with another platform (R or Excel)\n",
        "* It is easy to write the DataFrame back to a comma delimited file and other file formats.\n",
        "* We use the DataFrame member function, [my_DataFrame].to_csv()\n",
        "* The file will write to the working directory "
      ],
      "metadata": {
        "id": "Y_W0IVByUAZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('2D_MV_200wells_out.csv')"
      ],
      "metadata": {
        "id": "SB0-lPdLT5nn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}